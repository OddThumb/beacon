% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Pipe.R
\name{stream}
\alias{stream}
\title{Run full anomaly detection stream over multiple batches}
\usage{
stream(batch_set, arch_params, use_model = NA)
}
\arguments{
\item{batch_set}{A list of batches, each element being a named list of \code{ts} objects per detector.}

\item{arch_params}{A list of architecture and configuration parameters.
Typically created by \code{\link{config_pipe}}.}

\item{use_model}{(Optional) A named list of pre-trained per-detector statistics
to initialize \code{ustat}. Default is \code{NA}, meaning no pretrained model.}
}
\value{
A named list containing:
\describe{
  \item{\code{res.net}}{Final detector-wise detection results.}
  \item{\code{coinc.lis}}{List of coincidence analysis results per batch.}
  \item{\code{model}}{Final per-detector accumulated statistics (i.e., last \code{ustat}).}
  \item{\code{arch_params}}{The configuration object used in the run.}
  \item{\code{lambda_plot}}{List of plots for \eqn{\lambda_a} and \eqn{\lambda_c}.}
  \item{\code{summary}}{Final per-detector statistical summary as a data.frame.}
  \item{\code{eta}}{List of elapsed times (in seconds) for each batch.}
}
}
\description{
Executes the anomaly detection pipeline across a sequence of batches for multiple detectors.
For each batch, it applies the \code{\link{pipe_net}} function, accumulates detection results,
performs coincidence analysis, and optionally incorporates pre-trained models.
}
\details{
This function initializes the pipeline via \code{\link{init_pipe}}, registers
parallel execution with \code{foreach} using a SOCK cluster, and iteratively
calls \code{\link{pipe_net}} on each batch.

After processing all batches, it aggregates per-detector statistics,
terminates parallel backend, and visualizes lambda trajectories via
\code{\link{plot_lambda}}.

The output \code{model} can be reused as \code{use_model} for transfer learning.
}
\examples{
\dontrun{
  # Assume batch_set and arch_params are prepared
  result <- stream(batch_set, arch_params)
  result$summary   # Show summary statistics
  result$model     # Save model for reuse
}

}
